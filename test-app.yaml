apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: test-app
  namespace: default
spec:
  type: Java
  mode: cluster
  image: "spark:3.1.2"
  imagePullPolicy: Never
  mainClass: com.test.Application
  mainApplicationFile: "s3a://app/latest/test-app-0.0.1.jar"
  sparkVersion: "3.1.2"
  restartPolicy:
    type: Never
  volumes:
    - name: "spark-local-dir-1"
  sparkConf:
    "spark.hadoop.fs.s3a.access.key": "access-key"
    "spark.hadoop.fs.s3a.secret.key": "secret-key"
    "spark.hadoop.fs.s3a.endpoint": "http://minio:9000"
    "spark.hadoop.fs.s3a.path.style.access": "true"
    "spark.hadoop.fs.s3a.impl": "org.apache.hadoop.fs.s3a.S3AFileSystem"
    "spark.dynamicAllocation.enabled": "true"
    "spark.dynamicAllocation.shuffleTracking.enabled": "true"
  driver:
    cores: 1
    coreLimit: "1024m"
    memory: "512m"
    labels:
      version: 3.1.2
    serviceAccount: spark 
    envSecretKeyRefs:
      DB_PASSWORD:
        name: test-app-secret
        key: db_password
    envFrom:
      - configMapRef:
          name: test-configmap
    volumeMounts:
      - name: "spark-local-dir-1"
        mountPath: "/tmp/spark"
  executor:
    cores: 1
    instances: 1
    memory: "512m"
    labels:
      version: 3.1.2
    envSecretKeyRefs:
      DB_PASSWORD:
        name: test-app-secret
        key: db_password
    envFrom:
      - configMapRef:
          name: test-configmap
    volumeMounts:
      - name: "spark-local-dir-1"
        mountPath: "/tmp/spark"
         